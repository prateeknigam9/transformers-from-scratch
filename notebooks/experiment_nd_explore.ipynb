{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_450qu70wv6q"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/datasets/stefanlarson/outofscope-intent-classification-dataset?resource=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RNySDu2pwv6s"
      },
      "outputs": [],
      "source": [
        "# import kagglehub\n",
        "\n",
        "# kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evmT90sgwv6t",
        "outputId": "4e04a924-e13a-42e5-99b3-0b2a61896274"
      },
      "outputs": [
        {
          "ename": "KaggleApiHTTPError",
          "evalue": "404 Client Error.\n\nResource not found at URL: https://www.kaggle.com/datasets/stefanlarson/outofscope-intent-classification-dataset/versions/1\nPlease make sure you specified the correct resource identifiers.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\exceptions.py:58\u001b[0m, in \u001b[0;36mkaggle_api_raise_for_status\u001b[1;34m(response, resource_handle)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://www.kaggle.com/api/v1/datasets/download/stefanlarson/outofscope-intent-classification-dataset?dataset_version_number=1&file_name=/storage",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKaggleApiHTTPError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstefanlarson/outofscope-intent-classification-dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/storage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to dataset files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\datasets.py:28\u001b[0m, in \u001b[0;36mdataset_download\u001b[1;34m(handle, path, force_download)\u001b[0m\n\u001b[0;32m     26\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[0;32m     27\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\registry.py:23\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\http_resolver.py:117\u001b[0m, in \u001b[0;36mDatasetHttpResolver.__call__\u001b[1;34m(self, h, path, force_download)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# Downloading a single file.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(out_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 117\u001b[0m     \u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&file_name=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# TODO(b/345800027) Implement parallel download when < 25 files in databundle.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# Downloading the full archived bundle.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     archive_path \u001b[38;5;241m=\u001b[39m get_cached_archive_path(h)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\clients.py:157\u001b[0m, in \u001b[0;36mKaggleApiV1Client.download_file\u001b[1;34m(self, path, out_file, resource_handle, cached_path)\u001b[0m\n\u001b[0;32m    149\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_url(path)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    151\u001b[0m     url,\n\u001b[0;32m    152\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_user_agent()},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m(DEFAULT_CONNECT_TIMEOUT, DEFAULT_READ_TIMEOUT),\n\u001b[0;32m    156\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m--> 157\u001b[0m     \u001b[43mkaggle_api_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     total_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    159\u001b[0m     size_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\kagglehub\\exceptions.py:89\u001b[0m, in \u001b[0;36mkaggle_api_raise_for_status\u001b[1;34m(response, resource_handle)\u001b[0m\n\u001b[0;32m     81\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource not found at URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease make sure you specified the correct resource identifiers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Default handling\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m KaggleApiHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mKaggleApiHTTPError\u001b[0m: 404 Client Error.\n\nResource not found at URL: https://www.kaggle.com/datasets/stefanlarson/outofscope-intent-classification-dataset/versions/1\nPlease make sure you specified the correct resource identifiers."
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"stefanlarson/outofscope-intent-classification-dataset\",path='/storage')\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri3xldUkw8JJ",
        "outputId": "236f7324-842b-46da-98f0-269488d4a04a"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jusHNpdkwv6u"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CkzMcxOJwv6v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from model_blocks import *\n",
        "from pathlib import Path\n",
        "import torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import utils "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS0kuvdLwv6v"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM5ed027wv6v",
        "outputId": "74854ab3-b2fb-4507-8e47-a91f9ecdecb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssaSmkhOwv6w",
        "outputId": "d006427c-4515-4051-f11a-f09c2b542b15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1b47c185470>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_epochs = 20\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIqimY_cwv6w"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcgRZVD1wv6x",
        "outputId": "43e77e26-e100-482a-e387-10d4c6d55221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['is_test.json',\n",
              " 'is_train.json',\n",
              " 'is_val.json',\n",
              " 'oos_test.json',\n",
              " 'oos_train.json',\n",
              " 'oos_val.json']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(os.path.join(path, 'is_train.json'), 'r') as file:\n",
        "    train_data = json.load(file)\n",
        "with open(os.path.join(path, 'is_val.json'), 'r') as file:\n",
        "    val_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaEdcoglwv6x",
        "outputId": "4e6a6951-0ade-4e72-ab10-59dd8cf8c4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data:\n",
            "['what expression would i use to say i love you if i were an italian', 'translate']\n",
            "what expression would i use to say i love you if i were an italian\n",
            "translate\n",
            "\n",
            " validation data:\n",
            "['in spanish, meet me tomorrow is said how', 'translate']\n",
            "in spanish, meet me tomorrow is said how\n",
            "translate\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(train_data)):\n",
        "    print(\"Train data:\")\n",
        "    print(train_data[i])\n",
        "    print(train_data[i][0])\n",
        "    print(train_data[i][1])\n",
        "    print(\"\\n validation data:\")\n",
        "    print(val_data[i])\n",
        "    print(val_data[i][0])\n",
        "    print(val_data[i][1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_preprocessing(ds):\n",
        "    prompt = []\n",
        "    label = []\n",
        "    ds_upd = pd.DataFrame()\n",
        "    \n",
        "    for indiv_data in ds:\n",
        "        prompt.append(indiv_data[0])\n",
        "        label.append(indiv_data[1])\n",
        "    ds_upd[\"prompt\"] = prompt\n",
        "    ds_upd[\"label_str\"] = label\n",
        "    \n",
        "    unique_classes = ds_upd['label_str'].unique()\n",
        "    class_to_id = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "    ds_upd['label'] = ds_upd['label_str'].map(class_to_id)\n",
        "    \n",
        "    return ds_upd, unique_classes\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, unique_classes = data_preprocessing(train_data)\n",
        "val_data, unique_classes = data_preprocessing(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>label_str</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9745</th>\n",
              "      <td>do you know why i can't log into my bank account</td>\n",
              "      <td>account_blocked</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14662</th>\n",
              "      <td>i'm out of soap so will you order me some more</td>\n",
              "      <td>order</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9292</th>\n",
              "      <td>would you say that red lobster's pretty buy at...</td>\n",
              "      <td>how_busy</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13408</th>\n",
              "      <td>in my tank how much gas is there</td>\n",
              "      <td>gas</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2978</th>\n",
              "      <td>who is the creator of this ai</td>\n",
              "      <td>who_made_you</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  prompt        label_str  \\\n",
              "9745    do you know why i can't log into my bank account  account_blocked   \n",
              "14662     i'm out of soap so will you order me some more            order   \n",
              "9292   would you say that red lobster's pretty buy at...         how_busy   \n",
              "13408                   in my tank how much gas is there              gas   \n",
              "2978                       who is the creator of this ai     who_made_you   \n",
              "\n",
              "       label  \n",
              "9745      97  \n",
              "14662    146  \n",
              "9292      92  \n",
              "13408    134  \n",
              "2978      29  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from seaborn) (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\nigam\\anaconda3\\envs\\ml_dev\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='text_len'>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>label_str</th>\n",
              "      <th>label</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>can you tell me what to do as i am in the airp...</td>\n",
              "      <td>lost_luggage</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12563</th>\n",
              "      <td>i want to buy a plane ticket to travel from mi...</td>\n",
              "      <td>book_flight</td>\n",
              "      <td>125</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12565</th>\n",
              "      <td>i want to book a flight reservation from texas...</td>\n",
              "      <td>book_flight</td>\n",
              "      <td>125</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>can you find out if my application at smith ba...</td>\n",
              "      <td>application_status</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>i think we should reserve dad's regular table ...</td>\n",
              "      <td>restaurant_reservation</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9674</th>\n",
              "      <td>goodbye!</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11881</th>\n",
              "      <td>bonjour</td>\n",
              "      <td>greeting</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11899</th>\n",
              "      <td>salutations!</td>\n",
              "      <td>greeting</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11878</th>\n",
              "      <td>aloha</td>\n",
              "      <td>greeting</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9602</th>\n",
              "      <td>bye-bye</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  prompt  \\\n",
              "4249   can you tell me what to do as i am in the airp...   \n",
              "12563  i want to buy a plane ticket to travel from mi...   \n",
              "12565  i want to book a flight reservation from texas...   \n",
              "1535   can you find out if my application at smith ba...   \n",
              "2402   i think we should reserve dad's regular table ...   \n",
              "...                                                  ...   \n",
              "9674                                            goodbye!   \n",
              "11881                                            bonjour   \n",
              "11899                                       salutations!   \n",
              "11878                                              aloha   \n",
              "9602                                             bye-bye   \n",
              "\n",
              "                    label_str  label  text_len  \n",
              "4249             lost_luggage     42        28  \n",
              "12563             book_flight    125        26  \n",
              "12565             book_flight    125        24  \n",
              "1535       application_status     15        24  \n",
              "2402   restaurant_reservation     24        24  \n",
              "...                       ...    ...       ...  \n",
              "9674                  goodbye     96         1  \n",
              "11881                greeting    118         1  \n",
              "11899                greeting    118         1  \n",
              "11878                greeting    118         1  \n",
              "9602                  goodbye     96         1  \n",
              "\n",
              "[15000 rows x 4 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngrS2W0wv6y"
      },
      "source": [
        "#  Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizer setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4130, 4491, 2252, 5152, 5286, 579, 4190]\n",
            "class fair, chat, persons jfk disney trader\n"
          ]
        }
      ],
      "source": [
        "corpus = \" \".join(train_data[\"prompt\"])\n",
        "tokenizer = utils.selfTokenizer(corpus)\n",
        "print(tokenizer.encode(\"i need you to translate the sentence\"))\n",
        "print(tokenizer.decode([5140, 5500, 539, 3868, 420, 3175, 2041]))\n",
        "del tokenizer, corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could use our own self made tokenizer class, hwoever GPT-2 uses BytePair encoding as tokenizer, and we would follow the same, as it allows to handle out-of-vocab words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[72, 761, 345, 284, 15772, 262, 6827]\n",
            "i need you to translate the sentence\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"i need you to translate the sentence\",allowed_special=\"all\"))\n",
        "print(tokenizer.decode([72, 761, 345, 284, 15772, 262, 6827]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i need you to translate the sentence'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = utils.get_or_build_tokenizer(train_data)\n",
        "tokenizer.encode(\"i need you to translate the sentence\").ids\n",
        "tokenizer.decode([4, 21, 9, 6, 646, 7, 2704])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "train_data[\"text_len\"] = train_data['prompt'].apply(lambda x: len(tokenizer.encode(x).tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='text_len'>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.boxenplot(train_data['text_len'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>label_str</th>\n",
              "      <th>label</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4569</th>\n",
              "      <td>my car's been throwing cels that i think are o...</td>\n",
              "      <td>oil_change_when</td>\n",
              "      <td>45</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>i think we should reserve dad's regular table ...</td>\n",
              "      <td>restaurant_reservation</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>can you tell me what to do as i am in the airp...</td>\n",
              "      <td>lost_luggage</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14102</th>\n",
              "      <td>i want to rent the cheapest car for charlottes...</td>\n",
              "      <td>car_rental</td>\n",
              "      <td>141</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10636</th>\n",
              "      <td>i'd like you to book me a room in austin near ...</td>\n",
              "      <td>book_hotel</td>\n",
              "      <td>106</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9685</th>\n",
              "      <td>buhbye</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4626</th>\n",
              "      <td>correct</td>\n",
              "      <td>yes</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>yep</td>\n",
              "      <td>yes</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10828</th>\n",
              "      <td>weather</td>\n",
              "      <td>weather</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9691</th>\n",
              "      <td>tootles</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  prompt  \\\n",
              "4569   my car's been throwing cels that i think are o...   \n",
              "2402   i think we should reserve dad's regular table ...   \n",
              "4249   can you tell me what to do as i am in the airp...   \n",
              "14102  i want to rent the cheapest car for charlottes...   \n",
              "10636  i'd like you to book me a room in austin near ...   \n",
              "...                                                  ...   \n",
              "9685                                              buhbye   \n",
              "4626                                             correct   \n",
              "4600                                                 yep   \n",
              "10828                                            weather   \n",
              "9691                                             tootles   \n",
              "\n",
              "                    label_str  label  text_len  \n",
              "4569          oil_change_when     45        30  \n",
              "2402   restaurant_reservation     24        30  \n",
              "4249             lost_luggage     42        28  \n",
              "14102              car_rental    141        27  \n",
              "10636              book_hotel    106        27  \n",
              "...                       ...    ...       ...  \n",
              "9685                  goodbye     96         1  \n",
              "4626                      yes     46         1  \n",
              "4600                      yes     46         1  \n",
              "10828                 weather    108         1  \n",
              "9691                  goodbye     96         1  \n",
              "\n",
              "[15000 rows x 4 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.sort_values(by='text_len',ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136\n"
          ]
        }
      ],
      "source": [
        "max_seq_len = len(max(train_data['prompt'],key=len))\n",
        "print(max_seq_len)\n",
        "train_data = utils.promptDataset(tokenizer,train_data,max_seq_len+1)\n",
        "val_data = utils.promptDataset(tokenizer,val_data,max_seq_len+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=10,shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(train_data,batch_size=2,shuffle=False)\n",
        "# data_iter = iter(train_loader)\n",
        "# inputs, targets = next(data_iter)\n",
        "# print(\"Inputs:\\n\", inputs)\n",
        "# print(\"\\nTargets:\\n\", targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkI5q0pwv6z"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pmmLSKBlwv60"
      },
      "outputs": [],
      "source": [
        "def build_encoder_only_transformer(src_vocab_size, n_classes,\n",
        "                                   seq_len, embedding_dim=512,\n",
        "                                   N =6, h=8, dropout=0.01, d_ff=2048):\n",
        "\n",
        "    src_embed = InputEmbeddings(src_vocab_size,embedding_dim)\n",
        "    src_pos = PositionalEncoding(embedding_dim, seq_len, dropout)\n",
        "\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        self_attention_block = MultiHeadAttention(seq_len, embedding_dim, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_ff,embedding_dim, dropout)\n",
        "        enc = encoder_block(self_attention_block,feed_forward_block,dropout)\n",
        "        encoder_blocks.append(enc)\n",
        "\n",
        "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
        "    transformer = EncoderOnlyTransformer(src_embed, src_pos, encoder,\n",
        "                                         n_classes, src_vocab_size,\n",
        "                                         embedding_dim)\n",
        "\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Yyj3KgbRwv60"
      },
      "outputs": [],
      "source": [
        "def get_model(tokenizer,n_classes):\n",
        "    model = build_encoder_only_transformer(tokenizer.max_token_value, n_classes, max_seq_len)\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8kjbYgp2MeI",
        "outputId": "b76d98e2-e92c-4715-f981-bd206d20c619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n"
          ]
        }
      ],
      "source": [
        "print(len(unique_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'bool' object has no attribute 'sum'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m()\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
          ]
        }
      ],
      "source": [
        "([1,0,0] == [0,0,0]).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eWit9J6Owv60"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model,dataloader, device=device):\n",
        "    losses, acc, count = [], 0, 0\n",
        "    batch_iterator = tqdm(enumerate(dataloader),total=len(dataloader))\n",
        "    for idx, batch in batch_iterator:\n",
        "        encoder_input = batch[0].to(device)\n",
        "        label = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model.encode(encoder_input,None).to(device)\n",
        "        # output = output[:, -1, :] # Get predictions for the last token\n",
        "        loss = loss_fn(output, label).to(device)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # global_step += 1\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        predicted_class = torch.argmax(output, dim=-1)\n",
        "\n",
        "        batch_correct = (predicted_class == label).sum().item()\n",
        "        batch_accuracy = batch_correct / len(label)\n",
        "        acc += batch_correct\n",
        "        count += len(label)\n",
        "\n",
        "        batch_iterator.set_postfix({\"train_loss\": f\"{loss.item():6.3f}\",\n",
        "                                     \"batch_acc\": f\"{batch_accuracy:.4f}\",\n",
        "                                     \"train_acc\": f\"{acc/count:.4f}\"})\n",
        "\n",
        "    return np.mean(losses), acc/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oFR7q1i-CvMb"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_data_batch, device=device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data_batch:\n",
        "            encoder_input = batch[0].to(device)\n",
        "            label = batch[1].to(device)\n",
        "            output = model.encode(encoder_input, None)\n",
        "\n",
        "            # import pdb; pdb.set_trace()\n",
        "            # output = output[:, -1, :]  # Get predictions for the last token\n",
        "            loss = loss_fn(output, label).to(device)\n",
        "\n",
        "            predicted_class = torch.argmax(output, dim=-1)\n",
        "            batch_correct = (predicted_class == label).sum().item()\n",
        "            batch_accuracy = batch_correct / len(label)\n",
        "            acc = batch_correct\n",
        "            count = len(label)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "    return np.mean(losses), acc/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "28P00sv8CnVe"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, test_loader, epochs):\n",
        "    for ep in range(epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader)\n",
        "        val_loss, val_acc = evaluate_model(model, test_loader)\n",
        "        print(f'ep {ep}: val_loss={val_loss:.4f}, val_acc={val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxDNmOWcEkvO",
        "outputId": "2e61b540-175b-4e5e-e107-fa5f8a451720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "EncoderOnlyTransformer                                  --\n",
              "├─InputEmbeddings: 1-1                                  --\n",
              "│    └─Embedding: 2-1                                   25,731,072\n",
              "├─PositionalEncoding: 1-2                               --\n",
              "│    └─Dropout: 2-2                                     --\n",
              "├─Encoder: 1-3                                          --\n",
              "│    └─ModuleList: 2-3                                  --\n",
              "│    │    └─encoder_block: 3-1                          3,150,342\n",
              "│    │    └─encoder_block: 3-2                          3,150,342\n",
              "│    │    └─encoder_block: 3-3                          3,150,342\n",
              "│    │    └─encoder_block: 3-4                          3,150,342\n",
              "│    │    └─encoder_block: 3-5                          3,150,342\n",
              "│    │    └─encoder_block: 3-6                          3,150,342\n",
              "├─Linear: 1-4                                           76,950\n",
              "================================================================================\n",
              "Total params: 44,710,074\n",
              "Trainable params: 44,710,074\n",
              "Non-trainable params: 0\n",
              "================================================================================"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_model(tokenizer,n_classes=len(unique_classes))\n",
        "torchinfo.summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "D0XsBmB-Esey"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=10**-4,eps= 1e-9)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo4eYeDtEDUo",
        "outputId": "747bdfc1-3c6c-44f7-a523-55712e2947a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[51], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, test_loader, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, train_loader, test_loader, epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 3\u001b[0m         train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader)\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[49], line 9\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m label \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# output = output[:, -1, :] # Get predictions for the last token\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, label)\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\OneDrive\\Documents\\self\\classification\\transformer.py:21\u001b[0m, in \u001b[0;36mEncoderOnlyTransformer.encode\u001b[1;34m(self, x, src_mask)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,src_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos(x)\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x, src_mask)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\OneDrive\\Documents\\self\\classification\\common_blocks.py:11\u001b[0m, in \u001b[0;36mInputEmbeddings.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim)\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nigam\\anaconda3\\envs\\ml_dev\\Lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, val_loader, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltkVhL1wv60"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model, tokenizer, prompts, class_to_id):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for prompt in prompts:\n",
        "            enc_input_tokens = tokenizer.encode(prompt).ids\n",
        "            encoder_input = torch.tensor(enc_input_tokens, dtype=torch.int64).unsqueeze(0).to(device)\n",
        "\n",
        "            output = model.encode(encoder_input, None)\n",
        "            # output = output[:, -1, :]  # Get predictions for the last token\n",
        "            predicted_class = torch.argmax(output, dim=-1).item()\n",
        "            predictions.append(predicted_class)\n",
        "\n",
        "    # Map predicted classes back to text labels\n",
        "    id_to_class = {idx: cls for cls, idx in class_to_id.items()}\n",
        "    predicted_labels = [id_to_class[pred] for pred in predictions]\n",
        "    return predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_GoUQk5wv61"
      },
      "outputs": [],
      "source": [
        "def get_sample_prompts_and_labels(ds_upd, sample_size):\n",
        "\n",
        "    sampled_data = ds_upd.sample(n=sample_size)\n",
        "\n",
        "    prompts = sampled_data['prompt'].tolist()\n",
        "    actual_labels = sampled_data['completion'].map(lambda x: {v: k for k, v in class_to_id.items()}[x]).tolist()\n",
        "\n",
        "    return prompts, actual_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcVh4QNYwv61"
      },
      "outputs": [],
      "source": [
        "sample_size = 5\n",
        "\n",
        "sample_prompts, actual_labels = get_sample_prompts_and_labels(ds_upd, sample_size)\n",
        "\n",
        "predicted_labels = predict_labels(model, tokenizer, sample_prompts, class_to_id)\n",
        "\n",
        "for prompt, actual, predicted in zip(sample_prompts, actual_labels, predicted_labels):\n",
        "    print(f\"Prompt: {prompt}\\nActual Label: {actual}\\nPredicted Label: {predicted}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
